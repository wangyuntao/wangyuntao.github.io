[{"content":"","href":"/posts/","title":"文章"},{"content":"记录下日常的技术细节\n","href":"/%E5%85%B3%E4%BA%8E/","title":"关于"},{"content":" 本博客的内容也会同步到我的微信公众号，欢迎大家关注。\n微信公众号: ytcode\n ","href":"/","title":"\u003e "},{"content":"","href":"/authors/","title":"Authors"},{"content":"","href":"/categories/","title":"Categories"},{"content":"","href":"/tags/linux/","title":"Linux"},{"content":"","href":"/categories/linux%E7%B3%BB%E7%BB%9F%E7%A0%94%E7%A9%B6/","title":"Linux系统研究"},{"content":"首先，在linux内核的网络模块里维护着一个全局实例，用来存储所有和tcp相关的socket：\n// net/ipv4/tcp_ipv4.c struct inet_hashinfo tcp_hashinfo; 其次，在该实例的内部，又根据socket用途的不同，划分成四个hashtable：\n// include/net/inet_hashtables.h struct inet_hashinfo { // key是由本地地址、本地端口、远程地址、远程端口组成的四元组  // value是想要进行tcp通信的所有socket  // 比如正在建立连接的socket，正在传输数据的socket，以及正在关闭连接的socket  // 当内核收到一个tcp消息时，会先提取tcp消息头中的远程及本地的地址端口信息  // 然后以该信息作为key，在ehash中找对应的socket，如果该socket存在  // 则根据这个socket的当期状态以及tcp消息的内容，对该socket做后续的逻辑处理  struct inet_ehash_bucket *ehash; // key是本地端口  // value是一个集合对象，里面存放着所有正在使用该端口的socket  // 比如监听着某个端口的服务端socket  // 比如通过某个监听端口建立tcp连接的对应的本地socket（该socket和监听socket使用同样的本地端口）  // 该hashtable的作用是为了查找某个端口是否可以被使用  // 比如在我们执行bind操作时  // 比如在我们调用connect方法，操作系统帮我们挑选本地端口时  struct inet_bind_hashbucket *bhash; // key是由本地地址和本地端口组成的二元组  // value是对应的处于监听状态中的socket  // 该hashtable的作用是，当内核收到建立tcp连接请求时  // 可以从这里快速的查找到对应的服务端监听socket  struct inet_listen_hashbucket *lhash2; // key是本地端口  // value是对应的处于监听状态中的socket  // 由于该hashtable在tcp的主体逻辑中并不会被大量使用  // 所以下文不会过多介绍  struct inet_listen_hashbucket listening_hash[INET_LHTABLE_SIZE]; }; 由上可见，tcp_hashinfo实例最主要的用途就是根据不同条件，快速查找到对应的socket。\n在系统启动时，这个全局的tcp_hashinfo实例会在下面的方法中被初始化：\n// net/ipv4/tcp.c void __init tcp_init(void) { // 初始化tcp_hashinfo里的四个hashtable等信息 } 该tcp_hashinfo实例还会被赋值给另外一个全局实例tcp_prot中的h.hashinfo字段：\n// net/ipv4/tcp_ipv4.c struct proto tcp_prot = { // 在struct sock里会通过sk_prot字段引用该tcp_prot实例  // 也就是说，如果拿到任一个struct sock实例  // 就可以通过它的sk_prot字段获取tcp_prot实例  // 进而也就可以获取tcp_hashinfo实例  .h.hashinfo = \u0026amp;tcp_hashinfo, }; tcp_hashinfo中的各种hashtable用的就是最基本的数组链表结构，当socket要插入到一个hashtable中时，会以一个节点的形式，挂在该hashtable内部数组的某个槽位所指的链表里。\n在把socket添加到链表的过程中，操作系统会根据目标hashtable的不同，使用不同的socket结构体中的字段，为了便于对后文的理解，下面我们对这些字段做一个简单梳理：\n// include/net/sock.h struct sock { // 在内核中以struct sock结构体表示一个socket  struct sock_common __sk_common; #define sk_node __sk_common.skc_node // 在添加到listening_hash时使用 #define sk_nulls_node __sk_common.skc_nulls_node // 在添加到ehash时使用 #define sk_bind_node __sk_common.skc_bind_node // 在添加到bhash的value的owners时使用 #define sk_hash __sk_common.skc_hash // 该sock在添加到ehash时的hash值，由本地及远程的地址端口信息计算得来 } // include/net/inet_connection_sock.h struct inet_connection_sock { // 该结构体是struct sock的子类  struct inet_bind_bucket *icsk_bind_hash; // 指向该sock所属的bhash中的value（该sock会被放入该value的owners字段里）  struct hlist_node icsk_listen_portaddr_node; // 在添加到lhash2时使用 } 好，以上就是操作系统在管理tcp连接时，用到的所有的数据结构及相关字段。下面我们就以这些内容作为切入点，看下操作系统内的tcp机制是如何实现的。\n在tcp编程中，一般都分为客户端和服务端，我们先来看下服务端的相关操作。\n首先，要开启一个服务端，必须要经过两步，第一步是bind操作，用来指定我们要监听的端口，第二步是listen操作，用来告诉操作系统可以开始监听该端口进来的tcp连接了。\n我们先来看下bind操作是如何与tcp_hashinfo打交道的：\n// net/ipv4/inet_connection_sock.c int inet_csk_get_port(struct sock *sk, unsigned short snum) { // 该方法的调用栈：  // SYSCALL_DEFINE3(bind)  // __sys_bind  // inet_bind  // inet_csk_get_port  // 下面的hinfo就是全局实例tcp_hashinfo  struct inet_hashinfo *hinfo = sk-\u0026gt;sk_prot-\u0026gt;h.hashinfo; // 根据端口算出hash值，然后根据这个值找到bhash中对应的slot  head = \u0026amp;hinfo-\u0026gt;bhash[inet_bhashfn(net, port, hinfo-\u0026gt;bhash_size)]; // 遍历slot指向的链表，找到该port对应的值  inet_bind_bucket_for_each(tb, \u0026amp;head-\u0026gt;chain) if (net_eq(ib_net(tb), net) \u0026amp;\u0026amp; tb-\u0026gt;l3mdev == l3mdev \u0026amp;\u0026amp; tb-\u0026gt;port == port) goto tb_found; // 如果没有找到，说明现在还没有socket使用这个端口  // 创建一个新的value实例并放入到bhash中  // 用来表明这个端口现在有socket在用了  tb = inet_bind_bucket_create(hinfo-\u0026gt;bind_bucket_cachep, net, head, port, l3mdev); tb_found: // 如果tb里的owners字段不为空，说明当前有socket在使用这个端口  if (!hlist_empty(\u0026amp;tb-\u0026gt;owners)) { // 判断我们的socket和owners里的socket是否可以共享使用这个端口  // 如果不可以，则返回错误给用户  if (inet_csk_bind_conflict(sk, tb, true, true)) goto fail_unlock; } // 省略很多无关代码  // 在该方法的最后，会调用inet_bind_hash方法  // 方法内容会在下面描述  if (!inet_csk(sk)-\u0026gt;icsk_bind_hash) inet_bind_hash(sk, tb, port); } 再来看下上面提到的inet_bind_hash方法：\n// net/ipv4/inet_hashtables.c void inet_bind_hash(struct sock *sk, struct inet_bind_bucket *tb, const unsigned short snum) { // tb是上面方法中在bhash里获取的或新创建的一个value实例  // 它的owners字段存放的是所有正在使用该端口的socket  // 下面语句的意思是，把这个socket也加入到owners里  // 表明这个socket也在使用该端口  sk_add_bind_node(sk, \u0026amp;tb-\u0026gt;owners); // 将tb存放到该socket的icsk_bind_hash字段里  // 这样以后如果我们想要将该socket从bhash中移除时  // 就可以通过这个字段快速定位到该socket所属的bhash中value了  inet_csk(sk)-\u0026gt;icsk_bind_hash = tb; } 由上可见，tcp_hashinfo在bind操作中的作用就是用于检查指定端口是否可使用。\n下面我们再来看下listen操作：\n// net/ipv4/inet_hashtables.c int __inet_hash(struct sock *sk, struct sock *osk) { // 该方法的调用栈：  // SYSCALL_DEFINE2(listen)  // __sys_listen  // inet_listen  // inet_csk_listen_start  // inet_hash  // __inet_hash  // hashinfo就是全局实例tcp_hashinfo  struct inet_hashinfo *hashinfo = sk-\u0026gt;sk_prot-\u0026gt;h.hashinfo; // 根据本地端口，找到该socket在listening_hash中的slot  ilb = \u0026amp;hashinfo-\u0026gt;listening_hash[inet_sk_listen_hashfn(sk)]; // 将该socket添加到这个slot对应的链表中  else hlist_add_head_rcu(\u0026amp;sk-\u0026gt;sk_node, \u0026amp;ilb-\u0026gt;head); // 下面的方法后面另讲  inet_hash2(hashinfo, sk); } 再看下上面提到的inet_hash2方法：\n// net/ipv4/inet_hashtables.c static void inet_hash2(struct inet_hashinfo *h, struct sock *sk) { // 根据该socket的本地地址和本地端口  // 找到其在lhash2中所属的slot  ilb2 = inet_lhash2_bucket_sk(h, sk); // 将该socket加入到这个slot对应的链表中  else hlist_add_head_rcu(\u0026amp;inet_csk(sk)-\u0026gt;icsk_listen_portaddr_node, \u0026amp;ilb2-\u0026gt;head); } 由上可见，listen操作只是把对应的socket加入到tcp_hashinfo的listening_hash和lhash2中，供后面tcp连接时查询用。\n服务端的相关操作就是这些，我们再来看下客户端。\n客户端第一步要做的事就是连接服务器，所以我们看下对应的connect方法：\n// net/ipv4/inet_hashtables.c int __inet_hash_connect(struct inet_timewait_death_row *death_row, struct sock *sk, u32 port_offset, int (*check_established)(struct inet_timewait_death_row *, struct sock *, __u16, struct inet_timewait_sock **)) { // 该方法的调用栈  // SYSCALL_DEFINE3(connect)  // __sys_connect  // inet_stream_connect  // __inet_stream_connect  // tcp_v4_connect  // inet_hash_connect  // __inet_hash_connect  // hinfo是全局的tcp_hashinfo实例  struct inet_hashinfo *hinfo = death_row-\u0026gt;hashinfo; // 一般来说，connect操作我们都不会主动指定本地端口  // 而是让操作系统帮我们自由挑选  // 下面的方法就是用于获取操作系统自由挑选的本地端口的范围  // 该范围默认是 [32768-60999]  // 当前范围可由以下命令查看：  // $ cat /proc/sys/net/ipv4/ip_local_port_range  inet_get_local_port_range(net, \u0026amp;low, \u0026amp;high); // 依次检测范围内的端口，找到第一个可以使用的  // 第一个要检测的端口  port = low + offset; for (i = 0; i \u0026lt; remaining; i += 2, port += 2) { // 找到该端口对应的bhash中的slot  head = \u0026amp;hinfo-\u0026gt;bhash[inet_bhashfn(net, port, hinfo-\u0026gt;bhash_size)]; // 遍历该slot指向的链表，查看是否有人已经在使用该端口  inet_bind_bucket_for_each(tb, \u0026amp;head-\u0026gt;chain) { if (net_eq(ib_net(tb), net) \u0026amp;\u0026amp; tb-\u0026gt;l3mdev == l3mdev \u0026amp;\u0026amp; tb-\u0026gt;port == port) { // 如果该端口已经被人使用  // 那就检查一下使用者中是否有处于连接状态的socket  // 且该socket的tcp四元组和我们的socket的tcp四元组完全一致（tcp四元组唯一确定一个tcp连接）  // 如果有，则该端口不可用  // 如果没有，则可用  if (!check_established(death_row, sk, port, \u0026amp;tw)) goto ok; goto next_port; } } // 如果该端口没人用，我们就在bhash中新创建一个对象，表示我们要用  tb = inet_bind_bucket_create(hinfo-\u0026gt;bind_bucket_cachep, net, head, port, l3mdev); goto ok; next_port: } ok: // 该方法上面有讲过，主要就是将该socket与tb实例联系起来  // 详情可参考上面  inet_bind_hash(sk, tb, port); if (sk_unhashed(sk)) { // 该方法下面会详细看  inet_ehash_nolisten(sk, (struct sock *)tw); } }  再来看下上面提到的inet_ehash_nolisten方法：\n// net/ipv4/inet_hashtables.c bool inet_ehash_insert(struct sock *sk, struct sock *osk) { // hashinfo就是全局的tcp_hashinfo实例  struct inet_hashinfo *hashinfo = sk-\u0026gt;sk_prot-\u0026gt;h.hashinfo; // 根据本地和远程的地址端口信息算出该socket的hash值  // 并保存到sk的sk_hash字段里，供后续使用  sk-\u0026gt;sk_hash = sk_ehashfn(sk); // 根据该hash值找到ehash中对应的slot  head = inet_ehash_bucket(hashinfo, sk-\u0026gt;sk_hash); // 把该socket加入到该slot指向的链表中  if (ret) __sk_nulls_add_node_rcu(sk, list); } bool inet_ehash_nolisten(struct sock *sk, struct sock *osk) { bool ok = inet_ehash_insert(sk, osk); } 由上可见，tcp_hashinfo在connect操作里的作用是，先根据bhash和ehash里的信息，为该次connect操作挑选出一个合适的本地端口（该端口的使用也会被记录在bhash里），然后在syn消息发送给服务器之前，将该socket放入到ehash中，这样当内核收到服务器的应答消息时，就可以找到对应的socket了。\nconnect操作最终会发syn消息给服务器，所以下面我们就来看下服务器在收到这个syn消息时是如何处理的。\n在此之前，我们先讲一些铺垫性的内容。\n当操作系统收到任意tcp的消息时，都会调用下面的方法，找到该tcp消息所属的socket，然后再根据该socket的当前状态和tcp消息的内容做后续处理：\n// net/ipv4/tcp_ipv4.c int tcp_v4_rcv(struct sk_buff *skb) { struct sock *sk; // 该方法会从tcp_hashinfo中的各种hashtable中尝试找到对应的socket  // th-\u0026gt;source是发送方的本地端口  // th-\u0026gt;dest是接收方的本地端口  sk = __inet_lookup_skb(\u0026amp;tcp_hashinfo, skb, __tcp_hdrlen(th), th-\u0026gt;source, th-\u0026gt;dest, sdif, \u0026amp;refcounted); }  再看下__inet_lookup_skb方法：\n// include/net/inet_hashtables.h static inline struct sock *__inet_lookup_skb(struct inet_hashinfo *hashinfo, struct sk_buff *skb, int doff, const __be16 sport, const __be16 dport, const int sdif, bool *refcounted) { const struct iphdr *iph = ip_hdr(skb); return __inet_lookup(dev_net(skb_dst(skb)-\u0026gt;dev), hashinfo, skb, doff, iph-\u0026gt;saddr, sport, iph-\u0026gt;daddr, dport, inet_iif(skb), sdif, refcounted); } 该方法又调用了__inet_lookup方法：\nstatic inline struct sock *__inet_lookup(struct net *net, struct inet_hashinfo *hashinfo, struct sk_buff *skb, int doff, const __be32 saddr, const __be16 sport, const __be32 daddr, const __be16 dport, const int dif, const int sdif, bool *refcounted) { u16 hnum = ntohs(dport); struct sock *sk; // 该方法会根据本地和远程的地址端口信息  // 从tcp_hashinfo的ehash中找对应的socket  sk = __inet_lookup_established(net, hashinfo, saddr, sport, daddr, hnum, dif, sdif); // 如果在ehash中没有找到对应的socket，则调用下面的方法  // 从tcp_hashinfo的lhash2中找对应的处于listen状态的socket  return __inet_lookup_listener(net, hashinfo, skb, doff, saddr, sport, daddr, hnum, dif, sdif); } 好，铺垫性内容结束。\n当服务端收到客户端发来的syn包后，会先通过上述方法，在lhash2中找到对应的listen状态的socket（listen方法把这个socket放入到lhash2中的），然后执行下面的逻辑：\n// net/ipv4/tcp_input.c int tcp_conn_request(struct request_sock_ops *rsk_ops, const struct tcp_request_sock_ops *af_ops, struct sock *sk, struct sk_buff *skb) { // 该方法的调用栈  // tcp_v4_rcv  // tcp_v4_do_rcv  // tcp_rcv_state_process  // tcp_v4_conn_request  // 该方法的参数sk就是上面找到的处于listen状态的socket  // 服务端在收到syn消息后，并不是直接创建一个struct sock  // 而是创建一个struct request_sock，表示该socket还处于tcp三次握手过程中  struct request_sock *req; req = inet_reqsk_alloc(rsk_ops, sk, !want_cookie); if (fastopen_sk) { } else { if (!want_cookie) // 该方法会根据本地和远程的地址端口信息  // 将request_sock放到tcp_hashinfo里的ehash里  // 这样后续的消息就可以找到这个request_sock了  inet_csk_reqsk_queue_hash_add(sk, req, tcp_timeout_init((struct sock *)req)); } } 服务端在处理完syn消息后，会发synack给客户端，客户端收到synack消息后，会再次发ack给服务端，同时将客户端的socket状态设置为TCP_ESTABLISHED。\n由于客户端处理synack消息的逻辑不涉及到tcp_hashinfo里的内容，所以这里就不详细说了。\n再看下服务端在收到ack消息之后的逻辑。\n服务端在收到ack消息后，会先通过上面介绍过的__inet_lookup_skb方法，找到刚刚创建的request_sock，然后执行如下逻辑：\n// net/ipv4/tcp_ipv4.c struct sock *tcp_v4_syn_recv_sock(const struct sock *sk, struct sk_buff *skb, struct request_sock *req, struct dst_entry *dst, struct request_sock *req_unhash, bool *own_req) { // 该方法的调用栈  // tcp_v4_rcv  // tcp_check_req  // tcp_v4_syn_recv_sock  // 收到客户端的ack消息表示该tcp连接建立成功  // 下面的方法会根据request_sock创建一个真正的struct sock  struct sock *newsk; newsk = tcp_create_openreq_child(sk, req, skb); // 该方法会把新创建的socket放到tcp_hashinfo的bhash中  // 对应的端口就是监听socket所使用的端口  // 此时该端口对应的bhash中的value中的owners字段里包含监听socket和这个新创建的socket  if (__inet_inherit_port(sk, newsk) \u0026lt; 0) goto put_and_exit; // 在上面创建request_sock时，把它放到tcp_hashinfo的ehash里  // 到这里request_sock的任务已经完成  // 所以下面的方法会把request_sock从ehash中移除  // 而把新创建的socket放到ehash里  *own_req = inet_ehash_nolisten(newsk, req_to_sk(req_unhash)); } 到现在一个完整的tcp连接已经建立好了，我们再重新梳理下整个思路。\n首先，服务端的socket先执行了bind操作，把它自己放到了tcp_hashinfo的bhash中，然后执行了listen操作，把它自己放到了tcp_hashinfo的lhash2中。\n然后，客户端执行connect方法，把对应的socket放到了bhash和ehash中，然后发了syn消息给服务端。\n服务端收到syn后，先从lhash2中找到对应的listen状态的socket，然后又根据该socket和syn消息创建了request_sock，并放入ehash中，最后发synack给客户端。\n客户端收到synack后，先从ehash中找到对应的socket，然后把其状态设置为TCP_ESTABLISHED，最后又返回ack给服务端。\n服务端收到ack后，会先从ehash中找到之前创建的request_sock，然后根据该request_sock，创建真正的sock，最后将request_sock从ehash中移除，将新创建的sock放到bhash和ehash中。\n至此，一个tcp连接就建立成功。\n再之后，就是tcp连接的数据传输过程了，当操作系统收到对方发来的数据时，先根据tcp消息头里的地址端口等信息，从ehash中找到对应的socket，然后将该数据添加到这个socket的接受缓冲区里，这样用户就可以通过read等方法获取这些数据了。\n这就是在tcp连接建立成功之后，tcp内的逻辑对tcp_hashinfo的使用。\n下面我们再来看下在tcp的关闭流程中，tcp_hashinfo是如何被使用的。\n假设客户端先调用了close方法，主动关闭了连接，看下对应代码：\n// net/ipv4/tcp.c void tcp_close(struct sock *sk, long timeout) { // 该方法的调用栈  // SYSCALL_DEFINE1(close)  // __close_fd  // filp_close  // fput  // fput_many  // ____fput  // __fput  // sock_close  // __sock_release  // inet_release  // tcp_close  // 下面的方法会将socket状态设置为TCP_FIN_WAIT1  } else if (tcp_close_state(sk)) { // 发fin消息给对方  tcp_send_fin(sk); } } 服务端在收到fin包的处理逻辑为：\n// net/ipv4/tcp_input.c void tcp_fin(struct sock *sk) { // 该方法的调用栈  // tcp_v4_rcv  // tcp_v4_do_rcv  // tcp_rcv_established  // tcp_data_queue  // tcp_fin  switch (sk-\u0026gt;sk_state) { case TCP_ESTABLISHED: tcp_set_state(sk, TCP_CLOSE_WAIT); }  该方法将服务端socket的状态设置为TCP_CLOSE_WAIT，然后返回ack给客户端。\n客户端收到ack后的处理逻辑：\n// net/ipv4/tcp_input.c int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb) { // 该方法的调用栈  // tcp_v4_rcv  // tcp_v4_do_rcv  // tcp_rcv_state_process  switch (sk-\u0026gt;sk_state) { case TCP_FIN_WAIT1: { tcp_set_state(sk, TCP_FIN_WAIT2); break; } } 该方法收到ack后，将客户端对应的socket的状态设置为TCP_FIN_WAIT2。\n此时，假设服务器的应用层也调用了socket的close方法，该方法会执行以下逻辑：\n// net/ipv4/tcp.c void tcp_close(struct sock *sk, long timeout) { // 该方法的调用栈  // SYSCALL_DEFINE1(close)  // __close_fd  // filp_close  // fput  // fput_many  // ____fput  // __fput  // sock_close  // __sock_release  // inet_release  // tcp_close  // 下面的方法会将socket状态设置为TCP_LAST_ACK  } else if (tcp_close_state(sk)) { // 发fin消息给对方  tcp_send_fin(sk); } } 客户端收到fin消息的处理逻辑：\n// net/ipv4/tcp_input.c void tcp_fin(struct sock *sk) { // 该方法调用栈  // tcp_v4_rcv  // tcp_v4_do_rcv  // tcp_rcv_state_process  // tcp_data_queue  // tcp_fin  switch (sk-\u0026gt;sk_state) { case TCP_FIN_WAIT2: // 发送ack给对方  tcp_send_ack(sk); // 进入time wait逻辑处理  tcp_time_wait(sk, TCP_TIME_WAIT, 0); } } 继续看下tcp_time_wait方法：\n// net/ipv4/tcp_minisocks.c void tcp_time_wait(struct sock *sk, int state, int timeo) { // 类似于三次握手时服务端创建了request_sock  // 这里也根据当前sock创建了一个inet_timewait_sock  // 对应于处于time wait状态时的socket  struct inet_timewait_sock *tw; tw = inet_twsk_alloc(sk, tcp_death_row, state); if (tw) { // 从sock拷贝各种必要数据到inet_timewait_sock  // 进行time wait定时，超时后会调用inet_twsk_kill方法  // 将inet_timewait_sock从ehash和bhash中移除  inet_twsk_schedule(tw, timeo); // 该方法会将sock从ehash中移除  // 将inet_timewait_sock加入到ehash和bhash中  inet_twsk_hashdance(tw, sk, \u0026amp;tcp_hashinfo); } // 该方法会将sock从bhash中移除，并将其销毁  tcp_done(sk); } 好，客户端的逻辑就全部完成了，我们再看下服务端逻辑。\n当服务器处于TCP_LAST_ACK状态时，收到客户端的ack消息，进行下面的处理：\n// net/ipv4/tcp_input.c int tcp_rcv_state_process(struct sock *sk, struct sk_buff *skb) { // 该方法调用栈  // tcp_v4_rcv  // tcp_v4_do_rcv  // tcp_rcv_state_process  switch (sk-\u0026gt;sk_state) { case TCP_LAST_ACK: if (tp-\u0026gt;snd_una == tp-\u0026gt;write_seq) { // 该方法及其底层方法会将该sock从ebash和bhash中移除  tcp_done(sk); } } } 到这里，一个tcp连接就完全关闭了，并且前后端的socket都已经从tcp_hashinfo的ehash和bhash中移除。\n现在系统又回到tcp连接之前的状态，即只有一个服务端的socket处于listen状态，该socket同时被存放于tcp_hashinfo的bhash、lhash2及listening_hash里。\n我们看下当该listen状态的socket关闭的时候，对应的有关tcp_hashinfo的处理：\n// net/ipv4/tcp.c void tcp_set_state(struct sock *sk, int state) { // 该方法的调用栈  // SYSCALL_DEFINE1(close)  // __close_fd  // filp_close  // fput  // fput_many  // ____fput  // __fput  // sock_close  // __sock_release  // inet_release  // tcp_close  // tcp_set_state  switch (state) { case TCP_CLOSE: // 下面的方法会将socket从lhash2及listening_hash里移除  sk-\u0026gt;sk_prot-\u0026gt;unhash(sk); // 下面方法会将socket从bhash中移除  if (inet_csk(sk)-\u0026gt;icsk_bind_hash \u0026amp;\u0026amp; !(sk-\u0026gt;sk_userlocks \u0026amp; SOCK_BINDPORT_LOCK)) inet_put_port(sk); } } 至此，所有socket都已关闭，且tcp_hashinfo又回到了最原始的空状态。\n上文用了大量的篇幅讲述在tcp的各种操作中，tcp_hashinfo是如何被使用的。其实回过头来看一下，tcp_hashinfo在这其中的作用还是非常简单的，其主要目的就是辅助操作系统在各种情况下找到对应的socket。\n比如，在syn消息来时，要找到对应的listen状态的socket，用了tcp_hashinfo中的lhash2。\n比如，在syn消息之后的所有后续消息来时，要找到其对应的消息处理socket，用了tcp_hashinfo中的ehash。\n比如，在绑定端口或挑选端口时，要用到bhash来查询端口是否被占用。\n好，就这么多吧，文章到此就结束了。\n总体来说该篇文章是以tcp_hashinfo这个全局实例为中心，看了一下操作系统是如何管理tcp连接的。\n希望此文章能给同样处于内核研究的同学一些帮助。\n完。\n","href":"/posts/linux/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E6%98%AF%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86tcp%E8%BF%9E%E6%8E%A5%E7%9A%84/","title":"Linux系统研究 - 操作系统是如何管理tcp连接的"},{"content":"","href":"/tags/","title":"Tags"},{"content":"","href":"/authors/wangyuntao/","title":"wangyuntao"},{"content":"","href":"/tags/git/","title":"Git"},{"content":"","href":"/categories/git%E7%A4%BA%E4%BE%8B%E6%95%99%E7%A8%8B/","title":"Git示例教程"},{"content":"相关命令：\n# 比较当前工作区和Git的staging area里内容的区别 git diff # 比较Git的staging area和当前分支指向内容的区别 git diff --staged # 比较任意两次提交指向内容的区别 git diff \u0026lt;commit\u0026gt; \u0026lt;commit\u0026gt; 情景模拟：\n先执行下面的命令，创建一个测试用的Git仓库：\n# 创建一个空的Git仓库 mkdir repo cd repo git init # 提交一次 echo a1 \u0026gt; a.txt git add . git commit -m \u0026#34;Initial commit\u0026#34; 然后再执行下面的命令，对a.txt文件做一些修改：\necho a2 \u0026gt; a.txt 最后我们执行两次diff命令（参数不一样），看下输出有什么不同：\n$ git -P diff # 参数-P可以不管，下同 diff --git a/a.txt b/a.txt index da0f8ed..c1827f0 100644 --- a/a.txt +++ b/a.txt @@ -1 +1 @@ -a1 +a2 $ git -P diff --staged # 没有任何输出 由上可见，没有\u0026ndash;staged参数的diff命令输出了文件变化，而有\u0026ndash;staged参数的diff命令没有任何输出，即表示没有任何变化。\n这是因为，没有\u0026ndash;staged参数的diff命令比较的是工作区和Git的staging area里的内容的区别，因为我们上面修改了a.txt文件，即工作区里的内容变化了，但此时Git的staging area里的内容并没有任何变化，即还是原内容，所以该次diff命令就正确输出了我们对a.txt文件的修改。\n而有\u0026ndash;staged参数的diff命令比较的是Git的staging area和当前分支指向的内容的区别，因为此时这两个地方的内容都没有变化，所以该次diff命令没有任何输出。\n我们再执行下面的命令，看下这次不同的diff命令有怎样的输出：\n$ git add a.txt # 将a.txt的修改提交到Git的staging area $ git -P diff # 没有任何输出 $ git -P diff --staged diff --git a/a.txt b/a.txt index da0f8ed..c1827f0 100644 --- a/a.txt +++ b/a.txt @@ -1 +1 @@ -a1 +a2 这次的结果正好反过来了，有\u0026ndash;staged参数的diff命令有输出，而没有\u0026ndash;staged参数的diff命令没有输出。\n这是因为通过上面的git add命令，工作区里的文件内容已经同步到了Git的staging area里，所以此时这两个地方的文件内容是一样的，这样就导致了第一次diff命令没有任何输出。\n但正是因为这次同步导致的Git的staging area里的内容变化，使其和当前分支指向的内容不再相同（当前分支指向的还是原内容），所以有第二次diff命令就有了输出。\n继续上面的例子，我们再执行下面的命令：\n$ git commit -m 1 [master 867736c] 1 1 file changed, 1 insertion(+), 1 deletion(-) $ git -P diff # 无任何输出 $ git -P diff --staged # 无任何输出 因为这次先执行了git commit命令，导致staging area里的内容被同步到了Git仓库里，所以这两次diff命令都没有任何输出。\n注意，我们在描述git add和git commit命令时，用的都是同步文件内容到下一个区域，而不是添加这次的修改到下一个区域，这个概念是很重要的。\nGit在进行版本管理时，保存文件的地方分为三个区域，分别是工作区、staging area 和 Git仓库，我们要把这三个区域都想像成各自保存了所有文件的一份拷贝，而不是存放的一次次提交的零散的变化。\n当我们修改文件时，我们改动的是工作区里的内容。\n当我们执行git add命令时，我们是把对工作区的修改同步到了staging area里，使其当前内容和工作区内容相同。\n当我们执行git commit命令时，我们是把staging area里变动的部分同步到了Git仓库里，使Git仓库里的内容和工作区以及staging area里的内容都相同。\n所有命令的执行，目的都是将上一区域里变化的内容同步到下一区域，使这两个区域之间的内容完全相同。\n用这种方式思考Git的版本管理机制，对于我们日后理解Git的各种命令有非常大的帮助。\n话题太大，这里就不再展开了。\n最后我们再来看下不同提交之间的比较是什么样子的。\n我们先在当前Git仓库的基础上继续执行下面的命令：\n# 创建并切换到分支b git checkout -b b # 在分支b上连续提交两次 echo b1 \u0026gt; a.txt \u0026amp;\u0026amp; git commit -am b1 echo b2 \u0026gt;\u0026gt; a.txt \u0026amp;\u0026amp; git commit -am b2 # 切换回master分支 git checkout - # 在master分支上再连续提交两次 echo m1 \u0026gt; a.txt \u0026amp;\u0026amp; git commit -am m1 echo m2 \u0026gt;\u0026gt; a.txt \u0026amp;\u0026amp; git commit -am m2 执行完上述命令后，我们用下面的命令比较下当前b分支和master分支的区别：\n$ git -P diff master b diff --git a/a.txt b/a.txt index b5692e5..9b89cd5 100644 --- a/a.txt +++ b/a.txt @@ -1,2 +1,2 @@ -m1 -m2 +b1 +b2 看到了吧，这次的diff命令清晰的显示了两个分支对a.txt做的修改，以及他们导致的冲突。\n该命令在分支合并时是非常有用的，我们可以使用该命令在合并前看下被合并分支对当前分支的文件内容做了哪些修改。\ngit diff命令还有很多更好玩和更加强大的执行方式，限于篇幅原因，这里就不一一指出了，有兴趣的同学可以看下Git自带的文档，执行 git help diff 就可以看到了。\n完。\n","href":"/posts/git/diff/","title":"Git示例教程 - 灵活使用git diff命令"},{"content":"相关命令：\ngit config --global alias.别名 别名代表的真正命令 对于那些经常使用的，或者是特别复杂的Git命令，我们可以为其设置别名，这样在我们想要执行对应的Git命令时，只要执行这个别名命令就好了，简单方便。\n下面来演示下。\n当我们在命令行中，想要以图形化的方式查看当前分支的提交日志时，可以使用下面的命令：\n$ git log --graph --oneline * 8005803a2ca0 (HEAD -\u0026gt; master, origin/master, origin/HEAD) Merge tag \u0026#39;arc-5.4-rc6\u0026#39; of git://git.kernel.org/pub/scm/linux/kernel/git/vgupta/arc |\\ | * 5effc09c4907 ARC: perf: Accommodate big-endian CPU | * ab563bf54a4d ARC: [plat-hsdk]: Enable on-boardi SPI ADC IC | * 8ca8fa7f22dc ARC: [plat-hsdk]: Enable on-board SPI NOR flash IC * | 0365fb6baeb1 Merge branch \u0026#39;for-linus\u0026#39; of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid |\\ \\ | * | 09f3dbe47473 HID: i2c-hid: add Trekstor Primebook C11B to descriptor override | * | 08c453f6d073 HID: logitech-hidpp: do all FF cleanup in hidpp_ff_destroy() | * | 905d754c53a5 HID: logitech-hidpp: rework device validation # 省略输出 # 上面命令显示的是当前linux内核master分支的提交日志。\n该命令挺有用的，但就是参数太多了，此时我们就可以用别名的方式来简化该命令的使用。\n比如，我们可以为上面命令中的 log --graph --oneline 部分设置别名为 l，具体命令如下：\n$ git config --global alias.l \u0026#39;log --graph --oneline\u0026#39; 在执行完上面的命令后，别名就设置好了，这样当我们执行 git l 的时候，Git帮我们执行的真正命令其实是 git log --graph --oneline。\n我们来试下：\n$ git l * 8005803a2ca0 (HEAD -\u0026gt; master, origin/master, origin/HEAD) Merge tag \u0026#39;arc-5.4-rc6\u0026#39; of git://git.kernel.org/pub/scm/linux/kernel/git/vgupta/arc |\\ | * 5effc09c4907 ARC: perf: Accommodate big-endian CPU | * ab563bf54a4d ARC: [plat-hsdk]: Enable on-boardi SPI ADC IC | * 8ca8fa7f22dc ARC: [plat-hsdk]: Enable on-board SPI NOR flash IC * | 0365fb6baeb1 Merge branch \u0026#39;for-linus\u0026#39; of git://git.kernel.org/pub/scm/linux/kernel/git/hid/hid |\\ \\ | * | 09f3dbe47473 HID: i2c-hid: add Trekstor Primebook C11B to descriptor override | * | 08c453f6d073 HID: logitech-hidpp: do all FF cleanup in hidpp_ff_destroy() | * | 905d754c53a5 HID: logitech-hidpp: rework device validation # 省略输出 # 成功了，和原命令的输出完全一样。\n通过使用Git的命令别名，我们可以极大简化日常的Git操作，非常方便。\n希望你喜欢。\n","href":"/posts/git/command_alias/","title":"Git示例教程 - 命令别名"},{"content":"相关命令：\n# 图形化显示当前分支的提交日志 git log --graph --oneline # 图形化显示当前分支的提交日志及每次提交的变更内容 git log --graph --patch # 图形化显示所有分支的提交日志 git log --graph --oneline --all # 图形化显示所有分支的提交日志及每次提交的变更内容 git log --graph --patch --all 效果演示：\n我们先用下面的命令创建一个测试用的Git仓库：\n# 创建一个空的Git仓库 mkdir repo \u0026amp;\u0026amp; cd repo \u0026amp;\u0026amp; git init # master分支提交m1 echo m1 \u0026gt; m1.txt \u0026amp;\u0026amp; git add . \u0026amp;\u0026amp; git commit -m m1 # b分支提交b1、b2 git checkout -b b echo b1 \u0026gt; b1.txt \u0026amp;\u0026amp; git add . \u0026amp;\u0026amp; git commit -m b1 echo b2 \u0026gt; b2.txt \u0026amp;\u0026amp; git add . \u0026amp;\u0026amp; git commit -m b2 # 切换到master分支 git checkout master # master分支提交m2 echo m2 \u0026gt; m2.txt \u0026amp;\u0026amp; git add . \u0026amp;\u0026amp; git commit -m m2 # 合并b分支 git merge b --no-edit # master分支提交m3、m4 echo m3 \u0026gt; m3.txt \u0026amp;\u0026amp; git add . \u0026amp;\u0026amp; git commit -m m3 echo m4 \u0026gt; m4.txt \u0026amp;\u0026amp; git add . \u0026amp;\u0026amp; git commit -m m4 # b分支提交b3、b4 git checkout b echo b3 \u0026gt; b3.txt \u0026amp;\u0026amp; git add . \u0026amp;\u0026amp; git commit -m b3 echo b4 \u0026gt; b4.txt \u0026amp;\u0026amp; git add . \u0026amp;\u0026amp; git commit -m b4 # 切换到master分支 git checkout master 先看下当前分支提交日志的图形化效果：\n$ git -P log --graph --oneline * 1b95716 (HEAD -\u0026gt; master) m4 * 9629016 m3 * 960ae54 Merge branch \u0026#39;b\u0026#39; |\\ | * 5c4e7a0 b2 | * 82e6569 b1 * | cec7a59 m2 |/ * 3706b17 m1 再看下所有分支提交日志的图形化效果：\n$ git -P log --graph --oneline --all * 85cf84a (b) b4 * 6c72eb7 b3 | * 1b95716 (HEAD -\u0026gt; master) m4 | * 9629016 m3 | * 960ae54 Merge branch \u0026#39;b\u0026#39; | |\\ | |/ |/| * | 5c4e7a0 b2 * | 82e6569 b1 | * cec7a59 m2 |/ * 3706b17 m1 最后看下当前分支每次提交的变更内容：\n$ git -P log --graph --patch * commit 1b9571692938cae69e4cb6f1c90195629b99ee14 (HEAD -\u0026gt; master) | Author: wangyuntao \u0026lt;wyt.daily@gmail.com\u0026gt; | Date: Tue Oct 29 17:58:06 2019 +0800 | | m4 | | diff --git a/m4.txt b/m4.txt | new file mode 100644 | index 0000000..995fb87 | --- /dev/null | +++ b/m4.txt | @@ -0,0 +1 @@ | +m4 | * commit 96290165e6cf0869a7cb5f74dd84596e5b156017 | Author: wangyuntao \u0026lt;wyt.daily@gmail.com\u0026gt; | Date: Tue Oct 29 17:58:06 2019 +0800 | | m3 | | diff --git a/m3.txt b/m3.txt | new file mode 100644 | index 0000000..e5c9ce9 | --- /dev/null | +++ b/m3.txt | @@ -0,0 +1 @@ | +m3 | * commit 960ae547f7751191c9d30e17eac2fbb85589d778 |\\  Merge: cec7a59 5c4e7a0 | | Author: wangyuntao \u0026lt;wyt.daily@gmail.com\u0026gt; | | Date: Tue Oct 29 17:58:06 2019 +0800 | | | | Merge branch \u0026#39;b\u0026#39; | | | * commit 5c4e7a015a519e60134fe2d7895590a756887d4b | | Author: wangyuntao \u0026lt;wyt.daily@gmail.com\u0026gt; | | Date: Tue Oct 29 17:58:06 2019 +0800 | | | | b2 | | | | diff --git a/b2.txt b/b2.txt | | new file mode 100644 | | index 0000000..e6bfff5 | | --- /dev/null | | +++ b/b2.txt | | @@ -0,0 +1 @@ | | +b2 | | | * commit 82e6569460ce15d46b5f7d44fa4b68080bf952a6 | | Author: wangyuntao \u0026lt;wyt.daily@gmail.com\u0026gt; | | Date: Tue Oct 29 17:58:06 2019 +0800 | | | | b1 | | | | diff --git a/b1.txt b/b1.txt | | new file mode 100644 | | index 0000000..c9c6af7 | | --- /dev/null | | +++ b/b1.txt | | @@ -0,0 +1 @@ | | +b1 | | * | commit cec7a592810edb921e602c214881e3e8d37bb449 |/ Author: wangyuntao \u0026lt;wyt.daily@gmail.com\u0026gt; | Date: Tue Oct 29 17:58:06 2019 +0800 | | m2 | | diff --git a/m2.txt b/m2.txt | new file mode 100644 | index 0000000..08bb233 | --- /dev/null | +++ b/m2.txt | @@ -0,0 +1 @@ | +m2 | * commit 3706b17072a7eb78f8093b36774c63fbcd9dc106 Author: wangyuntao \u0026lt;wyt.daily@gmail.com\u0026gt; Date: Tue Oct 29 17:58:06 2019 +0800 m1 diff --git a/m1.txt b/m1.txt new file mode 100644 index 0000000..63a911f --- /dev/null +++ b/m1.txt @@ -0,0 +1 @@ +m1 以上命令是不是比直接用git log命令直观多了呢？\n好了，命令行中图形化显示提交日志的内容到这里就结束了，希望对你有所帮助。\n","href":"/posts/git/log_graph/","title":"Git示例教程 - 命令行中图形化显示提交日志"},{"content":"相关命令：\n# 遍历本地仓库中的所有分支，如果该分支在远程仓库中不存在，则在远程仓库中创建该分支 # 遍历远程仓库中的所有分支，如果该分支在本地仓库中不存在，则在远程仓库中删除该分支 git push --all --prune # 遍历远程仓库中的所有分支，如果该分支在本地仓库中没有对应的远程追踪分支，则在本地仓库中创建该分支 # 遍历本地仓库中的所有远程追踪分支，如果该分支在远程仓库中没有对应的分支，则将其删除 git fetch --prune 情景模拟：\n为了方便测试，我们先在GitHub上创建一个名为git-test-repo的仓库，然后将其克隆到本地，之后，我们再用相应的命令创建一个测试分支，并将其同步到远端，具体命令如下：\n$ git clone https://github.com/wangyuntao/git-test-repo.git repo1 # 省略输出 # $ cd repo1 $ git push origin master:b3 # 创建一个远程分支b3 # 省略输出 # $ git -P branch -avv # 查看当前分支状态 * master ab5a63d [origin/master] Initial commit remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/b3 ab5a63d Initial commit remotes/origin/master ab5a63d Initial commit 我们再打开一个终端，将该仓库再克隆一份到本地备用：\n$ git clone https://github.com/wangyuntao/git-test-repo.git repo2 # 省略输出 # $ cd repo2 $ git -P branch -avv * master ab5a63d [origin/master] Initial commit remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/b3 ab5a63d Initial commit remotes/origin/master ab5a63d Initial commit 现在我们回到repo1中，执行下面的命令：\n$ git branch b1 # 创建本地分支b1 $ git branch b2 # 创建本地分支b2 $ git push --all --prune # 将本地分支的添加删除状态同步到远程 Total 0 (delta 0), reused 0 (delta 0) To https://github.com/wangyuntao/git-test-repo.git - [deleted] b3 * [new branch] b1 -\u0026gt; b1 * [new branch] b2 -\u0026gt; b2 $ git -P branch -avv # 查看当前的分支状态 b1 ab5a63d Initial commit b2 ab5a63d Initial commit * master ab5a63d [origin/master] Initial commit remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/b1 ab5a63d Initial commit remotes/origin/b2 ab5a63d Initial commit remotes/origin/master ab5a63d Initial commit 由上可见，因为本地仓库中没有b3分支，所以 git push \u0026ndash;all \u0026ndash;prune 命令删除了远程仓库中的b3分支，又因为本地仓库中新建了b1和b2分支，所以该命令在远程仓库中也创建了这两个分支。\n现在我们再切换到repo2，执行下面的命令：\n$ git branch b3 origin/b3 # 创建远程追踪分支origin/b3的本地分支b3 Branch \u0026#39;b3\u0026#39; set up to track remote branch \u0026#39;b3\u0026#39; from \u0026#39;origin\u0026#39;. $ git -P branch -avv b3 ab5a63d [origin/b3] Initial commit * master ab5a63d [origin/master] Initial commit remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/b3 ab5a63d Initial commit remotes/origin/master ab5a63d Initial commit $ git fetch --prune # 将远程分支的添加删除状态同步到本地 From https://github.com/wangyuntao/git-test-repo - [deleted] (none) -\u0026gt; origin/b3 * [new branch] b1 -\u0026gt; origin/b1 * [new branch] b2 -\u0026gt; origin/b2 $ git -P branch -avv b3 ab5a63d [origin/b3: gone] Initial commit * master ab5a63d [origin/master] Initial commit remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/b1 ab5a63d Initial commit remotes/origin/b2 ab5a63d Initial commit remotes/origin/master ab5a63d Initial commit 由上可见，因为远程仓库中的b3分支被删除，并且又创建了b1和b2分支，所以 git fetch \u0026ndash;prune 命令删除了本地仓库中的远程追踪分支 origin/b3（但没有删除本地分支b3），并创建了远程追踪分支 origin/b1 和 origin/b2。\n到这里，有关本地仓库和远程仓库分支添加删除状态的同步就讲完了，希望对你有所帮助。\n","href":"/posts/git/branch_sync/","title":"Git示例教程 - 同步本地分支的添加删除状态到远程（或反之）"},{"content":"相关命令：\ngit branch -d 要删除的分支 # 删除本地分支 git branch -D 要删除的分支 # 强制删除本地分支 git push -d origin 要删除的分支 # 删除远程分支 情景模拟：\n为了方便测试，我们先在GitHub上创建一个名为git-test-repo的仓库，然后将其克隆到本地，并看下其当前的分支情况：\n$ git clone https://github.com/wangyuntao/git-test-repo.git Cloning into 'git-test-repo'... # 省略部分输出 # $ cd git-test-repo $ git -P branch -avv * master ab5a63d [origin/master] Initial commit remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/master ab5a63d Initial commit  由上可见，该仓库目前只有本地分支master，其对应的远程分支为origin/master（就是该仓库在GitHub上的master分支）。\n下面我们用上一篇文章中介绍过的命令，创建一个测试分支，并同步到远端：\n$ git branch b1 $ git push --set-upstream origin b1 # 省略输出 # $ git -P branch -avv b1 ab5a63d [origin/b1] Initial commit * master ab5a63d [origin/master] Initial commit remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/b1 ab5a63d Initial commit remotes/origin/master ab5a63d Initial commit 由上可见，我们创建了一个本地分支b1，然后将其同步到了GitHub上（orgin/b1）。\n下面我们来测试下对应的删除命令。\n先删除本地分支：\n$ git branch -d b1 # 删除本地分支b1 Deleted branch b1 (was ab5a63d). $ git -P branch -avv # 查看当前分支情况 * master ab5a63d [origin/master] Initial commit remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/b1 ab5a63d Initial commit remotes/origin/master ab5a63d Initial commit 由上可见，本地的b1分支已经没有了，但其对应的远程分支origin/b1还在。\n我们再用下面的命令删除其对应的远程分支：\n$ git push -d origin b1 # 删除远端的b1分支 To https://github.com/wangyuntao/git-test-repo.git - [deleted] b1 $ git -P branch -avv # 查看当前的分支情况 * master ab5a63d [origin/master] Initial commit remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/master ab5a63d Initial commit 由上可见，b1对应的远程分支origin/b1也被删除了，此时如果我们到GitHub上看一下的话，也会发现，b1分支已经没有了。\n好了，到这里有关本地分支及远程分支的删除操作就已经讲完了，希望对你有所帮助。\n","href":"/posts/git/delete_branch/","title":"Git示例教程 - 删除本地分支及远程分支"},{"content":"相关命令：\ngit branch 新分支名 # 基于当前分支创建一个新分支 git push --set-upstream origin 新分支名 # 将新分支推送到远端 情景模拟：\n为了方便测试，我们先在GitHub上创建一个名为git-test-repo的仓库，然后将其克隆到本地，并看下其当前的分支情况：\n$ git clone https://github.com/wangyuntao/git-test-repo.git Cloning into \u0026#39;git-test-repo\u0026#39;... # 省略部分输出 # $ cd git-test-repo $ git -P branch -avv * master ab5a63d [origin/master] Initial commit remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/master ab5a63d Initial commit 由上可见，该仓库目前有个本地分支master，其对应的远程分支为origin/master（就是该仓库在GitHub上的master分支）。\n现在我们基于master分支，再创建一个分支b1：\n$ git branch b1 # 创建分支b1 $ git -P branch -avv # 查看当前分支情况 b1 ab5a63d Initial commit * master ab5a63d [origin/master] Initial commit remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/master ab5a63d Initial commit 由上可见，该仓库现在多了一个本地分支b1，但其目前并没有对应的远程分支。\n下面我们用git push命令，为b1创建一个远程分支。\n$ git push --set-upstream origin b1 # 将本地b1分支推送到远端 # 省略输出 # $ git -P branch -avv # 查看当前分支情况 b1 ab5a63d [origin/b1] Initial commit * master ab5a63d [origin/master] Initial commit remotes/origin/HEAD -\u0026gt; origin/master remotes/origin/b1 ab5a63d Initial commit remotes/origin/master ab5a63d Initial commit 由上可见，在执行完上面的git push命令后，本地b1分支就有了对应的远程分支origin/b1。\n此时，如果我们到GitHub上的仓库去看下的话，也是能找到这个分支的。\n这样，一个本地分支对应的远程分支就创建成功了。\n","href":"/posts/git/create_branch/","title":"Git示例教程 - 创建本地分支及远程分支"},{"content":"如果只是修改上次提交的日志，可以直接使用下面的命令：\ngit commit --amend -m 新的提交日志 如果上次提交的内容有误或者不全，想要修改上次提交中文件的内容，或是添加新的文件，可以执行下面的命令：\n# 先修改对应的文件 # git add 修改的文件或新文件 # 执行下面的命令，将这次修改的内容合并到上次提交 git commit --amend --no-edit 情景模拟：\n先使用下面的命令初始化一个测试用的Git仓库：\n# 初始化一个空的Git仓库 mkdir repo \u0026amp;\u0026amp; cd repo git init # 将a.txt加入到版本控制中 echo A1 \u0026gt; a.txt git add . git commit -m 1 执行完上面的命令后，你发现提交的日志不太友好，想要修改下，可以使用下面的命令：\n$ git commit --amend -m 正确的日志 [master e80dc2f] 正确的日志 Date: Wed Oct 23 17:17:41 2019 +0800 1 file changed, 1 insertion(+) create mode 100644 a.txt $ git -P log --pretty=oneline --abbrev-commit # 确认日志是修改了 e80dc2f (HEAD -\u0026gt; master) 正确的日志 由上可见，通过上面的命令，上次提交的日志信息得到了修复。\n假设我们又发现上次提交的a.txt文件里的内容是错的，且忘了提交b.txt文件，我们可以使用下面的命令修复上次提交：\n$ echo A2 \u0026gt; a.txt # 修复a.txt文件的内容 $ echo B1 \u0026gt; b.txt # 新建b.txt文件 $ git add . # 标记a.txt和b.txt都将在下次commit时提交 $ git commit --amend --no-edit # 将这次提交的内容合并到上次提交中 # 省略输出内容 # $ git -P log --pretty=oneline --abbrev-commit # 查看Git日志，确认只有一条 4f2b621 (HEAD -\u0026gt; master) 正确的日志 $ git -P log -p # 确认修复后的提交包含了我们刚刚做的修改 commit 4f2b621800332c0731f5340dc3a7945a09baf8b9 (HEAD -\u0026gt; master) Author: wangyuntao \u0026lt;wyt.daily@gmail.com\u0026gt; Date: Wed Oct 23 17:17:41 2019 +0800 正确的日志 diff --git a/a.txt b/a.txt new file mode 100644 index 0000000..3ce238a --- /dev/null +++ b/a.txt @@ -0,0 +1 @@ +A2 diff --git a/b.txt b/b.txt new file mode 100644 index 0000000..a19a027 --- /dev/null +++ b/b.txt @@ -0,0 +1 @@ +B1 由上可见，git comit \u0026ndash;amend -no-edit 命令将我们新的修改合并到了上一次提交中。\n","href":"/posts/git/modify_last_commit/","title":"Git示例教程 - 修改上次提交"},{"content":"最终命令：\ngit reset HEAD^ # 上次提交内容会被保存到工作目录 git reset --hard HEAD^ # 上次提交内容会被直接丢弃 情景模拟：\n先使用下面的命令初始化一个测试用的Git仓库：\n# 初始化一个空的Git仓库 mkdir repo \u0026amp;\u0026amp; cd repo git init # 将a.txt加入到版本控制中 echo A1 \u0026gt; a.txt git add . git commit -m 1 # 将a.txt的内容修改为A2并提交 echo A2 \u0026gt; a.txt git commit -am 2 执行完上面的命令后，看下当前的Git日志：\n$ git -P log --pretty=oneline --abbrev-commit 4490479 (HEAD -\u0026gt; master) 2 bf92587 1 假设我们想撤销上次提交，但上次提交的内容不丢弃，可以使用下面的命令：\n$ git reset HEAD^ Unstaged changes after reset: M a.txt $ git -P log --pretty=oneline --abbrev-commit bf92587 (HEAD -\u0026gt; master) 1 $ cat a.txt A2 由上可见，reset命令撤销了上次提交，并把这次提交的内容保存到了工作目录。\n如果我们想撤销上次提交，并且丢弃上次提交修改的内容，可以用另外一条reset命令，这个就不在这里演示了，有兴趣的同学可以自己试下。\n","href":"/posts/git/undo_last_commit/","title":"Git示例教程 - 撤销上次提交"},{"content":"最终命令：\ngit checkout HEAD a.txt # 撤销对a.txt文件的修改 git restore --source=HEAD --staged --worktree a.txt # 也可以使用这个命令 情景模拟：\n先使用下面的命令初始化一个测试用的Git仓库：\n# 初始化一个空的Git仓库 mkdir repo \u0026amp;\u0026amp; cd repo git init # 将a.txt加入到版本控制中 echo A1 \u0026gt; a.txt git add . git commit -m init # 修改a.txt，并把这次修改加入到Git的staging area中 echo A2 \u0026gt;\u0026gt; a.txt git add . # 修改a.txt，不把这次修改加入到Git的staging area中 echo A3 \u0026gt;\u0026gt; a.txt 执行完上面的命令后，看下该Git仓库的当前状态：\n$ git status On branch master Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) modified: a.txt Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) modified: a.txt 现在我们想撤销对a.txt文件的修改，可执行如下命令：\n$ git checkout HEAD a.txt Updated 1 path from b5ab058 $ git status On branch master nothing to commit, working tree clean $ cat a.txt A1 由上可见，checkout命令撤销了对a.txt文件的所有修改，包括staging area中的修改。\n","href":"/posts/git/undo_changes_to_one_file/","title":"Git示例教程 - 撤销对单个文件的修改"},{"content":"最终命令：\n$ git reset --hard # 撤销所有文件的修改（不算未进入版本控制的文件） $ git clean -fd # 删除所有未进入版本控制的文件 下面用一个例子展示下这两个命令的使用。\n先用下面的命令初始化一个测试用的Git仓库：\n$ mkdir repo $ cd repo $ git init # 初始化一个空Git仓库 $ echo a \u0026gt; f1.txt $ git add . $ git commit -m f1 # 将f1.txt加入到版本控制中 $ echo b \u0026gt; f1.txt # 修改f1.txt的内容 $ touch f2.txt # 创建新文件f2.txt，其并未进入到版本控制中 执行完上面的命令后，我们已经有了一个可供测试的Git仓库。\n再用下面的命令看下文件的变化情况：\n$ git status -s M f1.txt ?? f2.txt $ git -P diff diff --git a/f1.txt b/f1.txt index 7898192..6178079 100644 --- a/f1.txt +++ b/f1.txt @@ -1 +1 @@ -a +b 由上可见，f1.txt的内容由a变为了b，f2.txt是新创建的，还未进入到版本控制中。\n现在执行上面的撤销命令，看下是如何撤销修改的：\n$ git reset --hard HEAD is now at 5b3c640 f1 $ git status -s ?? f2.txt $ git clean -fd Removing f2.txt $ git status On branch master nothing to commit, working tree clean 由上可见，执行完reset命令后，f1.txt文件的修改被撤销，但f2.txt文件还在。\n执行完clean命令后，f2.txt文件也不在了。\n至此，两条命令撤销了对所有文件的修改，Git仓库回到了原始状态。\n","href":"/posts/git/undo_changes_to_all_files/","title":"Git示例教程 - 撤销对所有文件的修改"},{"content":"","href":"/page/","title":"Pages"},{"content":"","href":"/search/","title":"Search"},{"content":"","href":"/series/","title":"Series"}]
